---
title: "crosswords"
author: "paolo pasco"
date: "3/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(janitor)
library(readxl)
library(broom)
library(gt)
library(tidytext)
library(gender)
```

```{r reading, echo=FALSE}
nyt <- read_excel("raw-data/NYT_Crossword_2009_2016.xlsx") %>%
  select(-Explanation) %>%
  mutate(Word = map(Word, ~ str_split(., "[(]"))) %>%
  unnest(Word) %>%
  mutate(Word = map(Word, ~ .[1])) %>%
  mutate(Word = map(Word, ~ str_replace_all(., "[[:punct:]]|\\s", ""))) %>%
  mutate(Outlet = "NYT") %>%
  select(-Total)

# Finding the top ten most frequently appearing words in the NY times crossword.
# Surprised personally that ONO isn't on the list, but it falls just short at 59
# appearances. Still hoping to do the same with the LA times crossword, but
# scraping is proving to be an interesting process. Added some of the scraped LA
# times .csv file to show the state of things; still working on how to separate
# them into lines

nyttop10 <- nyt %>%
  unnest(Word) %>%
  group_by(Word) %>%
  summarize(times=n()) %>%
  arrange(desc(times)) %>%
  slice(1:10)

# Slider for date
# Different difficulty for word length?

# Creating the graph! Stole the labeling idea from the latest problem set, so
# thank you very much for that.

ggplot(nyttop10, aes(x=reorder(Word, -times), y=times)) + geom_col() +
  xlab("Word") +
  ylab("Number of Appearances") +
  ggtitle("Ten most common words in the New York Times crossword",
          subtitle="Based on crosswords from 2009-2016") +
  geom_text(aes(y=times + 3, label=times))
```

```{r lat, echo = FALSE}

latimes <- read.csv("raw-data/latimes2.csv", header=FALSE,
                    col.names = c("web.scraper.start.url", "clues"))

latimes2 <- latimes %>%
  
  # Getting the clues onto their own lines
  
  mutate(clues = map(clues, ~ str_split(., "[1234567890]+[.]"))) %>%
  unnest(clues) %>%
  unnest(clues) %>%
  mutate(clues = map(clues, ~str_split(., "  "))) %>%
  unnest(clues) %>%
  mutate(Clue = map(clues, ~.[2]),
         Word = map(clues, ~.[3])) %>%
  filter(!is.na(Word)) %>%
  select(-c(clues)) %>%
  
  # Getting parentheticals out of words
  mutate(Word = map(Word, ~ str_split(., "[ ]+[(]"))) %>%
  unnest(Word) %>%
  mutate(Word = map(Word, ~ .[1])) %>%
  mutate(Word = map(Word, ~ str_replace_all(., "[[:punct:]]|\\s", ""))) %>%
  
  # Separating out weekdays, getting dates into workable format
  
  rename(date = web.scraper.start.url)%>%
  mutate(date = map(date, ~str_split(., "/"))) %>%
  unnest(date) %>%
  mutate(Year = as.double(map_chr(date, ~ .[4])),
         date = map(date, ~ paste(.[4],.[5],.[6], sep = "-"))) %>%
  mutate(date = map(date, ~ as.Date(.)),
         Weekday = map_chr(date, ~weekdays(., abbreviate=TRUE))) %>%
  mutate(date = map(date, ~ as.character(.))) %>%
  unnest(Clue) %>%
  mutate(Outlet = "LAT")
```

```{r binding, echo=FALSE}
joined <- bind_rows(nyt, select(latimes2, -date))
```

```{r analyze, echo=FALSE}

# Function that finds the length of a given entry, stripping spaces and punctuation
wordlen <- function(word) {
  new <- str_replace_all(word, "[[:punct:]]|\\s", "")
  str_length(new)
}

# Average word length vs. day of week

total_length <- function(x) {
   total_temp <- mutate(x, length = wordlen(x$Word))
   summarize(total_temp, sum = sum(total_temp$length))
}

# Finding the average word length by day of week in LA Times crosswords

latimes_avg <- latimes2 %>%
  mutate(length = wordlen(Word)) %>%
  group_by(Year, Weekday) %>%
  summarize(avg_length = sum(length)/n())

# Graphing average word length by day of week in LA Times crosswords

latimes_avg %>%
  mutate(Weekday = fct_relevel(Weekday, "Mon", "Tue", "Wed", "Thu",
                               "Fri", "Sat", "Sun")) %>%
  ggplot(aes(x = Weekday, y = avg_length)) +
  geom_boxplot() +
  labs(x = "Weekday", y = "Average Word Length",
       title = "Average Word Length of LAT Crosswords by Weekday")

# Doing the same for NYT puzzles

nyt_avg <- nyt %>%
  mutate(length = wordlen(Word)) %>%
  group_by(Year,Weekday) %>%
  summarize(avg_length = sum(length)/n())

nyt_avg %>%
  mutate(Weekday = fct_relevel(Weekday, "Mon", "Tue", "Wed", "Thu",
                               "Fri", "Sat", "Sun")) %>%
  ggplot(aes(x = Weekday, y = avg_length)) +
  geom_boxplot() +
  labs(x = "Weekday", y = "Average Word Length",
       title = "Average Word Length of NYT Crosswords by Weekday")

```

```{r regression}
# Working with just LA times, since I am able to get specific dates
lat_reg <- latimes2 %>%
  mutate(length = wordlen(Word)) %>%
  unnest(date) %>%
  group_by(date, Weekday) %>%
  summarize(avg_length = sum(length)/n())

lat_model <- lm(avg_length ~ Weekday, data = lat_reg)


lat_model2 <- lat_model %>%
  tidy(conf.int=TRUE) %>%
  select(term, estimate, conf.low, conf.high) %>%
  gt() %>%
  tab_header(
    title = "Regression on Day of Week versus Word Length",
    subtitle = "Based on LA Times crosswords from 2013-2016"
  ) %>%
  cols_label(
    term = "Weekday",
    estimate = "Estimate",
    conf.low = "Lower",
    conf.high = "Upper"
  ) %>%
  fmt_number(
    columns = 2:4,
    decimals = 2
  )

lat_model2 
```

```{r writing, echo = FALSE}
write_rds(latimes2, "crossword_shiny/latimes.rds")
write_rds(nyt, "crossword_shiny/nytimes.rds")
write_rds(joined, "crossword_shiny/joined.rds")
```

```{r uniqueness, echo = FALSE}

# Word Length vs difficulty
# See Shiny app

```

```{r references, echo = FALSE}

# Does the LA Times crossword reference certain people/places more than the NY
# Times puzzle? What about geographic/country/gender diversity of references?

# Splitting each clue into individual words
all_clues <- joined %>%
  select(Outlet, Clue) %>%
  unnest_tokens("Word", Clue)

# Loading in a dataset of the 100 most popular male and female
# names, for gender analysis.
name_tab = read.csv("raw-data/names.csv")

# Reading in name data
clues_names <- all_clues %>%
  filter(Word %in% name_tab$Male | Word %in% name_tab$Female) %>%
  mutate(gender = map(Word, ~ifelse(. %in% name_tab$Male, "Male", "Female"))) %>%
  unnest(gender) %>%
  group_by(Outlet, Word, gender) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

# Writes this to an .rds file
write_rds(clues_names, "crossword_shiny/names.rds")

graphnames <- clues_names %>%
  ungroup %>%
  filter(Outlet == "NYT") %>%
  slice(1:50)

ggplot(graphnames, aes(reorder(Word, -count), count, 
                       fill = gender)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 6)) +
  xlab("Name") +
  ylab("Count")

```
